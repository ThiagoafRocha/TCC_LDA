{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b542615-f077-40d7-ab84-bbc4e70ba255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('run', 0.06426276329882184),\n",
      "   ('file', 0.06328097108175651),\n",
      "   ('window', 0.04926811852909675),\n",
      "   ('raspberry_pi', 0.03641556586933238),\n",
      "   ('build', 0.034630489111031774),\n",
      "   ('core', 0.02552659764369868),\n",
      "   ('script', 0.021063905747947163),\n",
      "   ('version', 0.02079614423420207),\n",
      "   ('instal', 0.019011067475901464),\n",
      "   ('project', 0.017672259907176007)]),\n",
      " (1,\n",
      "  [('app', 0.09259617243379084),\n",
      "   ('application', 0.08563696114440364),\n",
      "   ('android', 0.04716798762806882),\n",
      "   ('project', 0.04243185772279142),\n",
      "   ('work', 0.02696694374637541),\n",
      "   ('method', 0.02687028803402281),\n",
      "   ('java', 0.02368064952638701),\n",
      "   ('find', 0.02184419099168761),\n",
      "   ('develop', 0.021070945292866808),\n",
      "   ('run', 0.01875120819640441)]),\n",
      " (2,\n",
      "  [('create', 0.06015602970203966),\n",
      "   ('command', 0.052824513582103584),\n",
      "   ('request', 0.052730519785694145),\n",
      "   ('aw', 0.048406805150860044),\n",
      "   ('update', 0.044741047090892),\n",
      "   ('thing', 0.04436507190525425),\n",
      "   ('api', 0.025754300216185733),\n",
      "   ('type', 0.02331046150954037),\n",
      "   ('http', 0.022182535952627126),\n",
      "   ('call', 0.018892753078296833)]),\n",
      " (3,\n",
      "  [('client', 0.08198292385433002),\n",
      "   ('message', 0.056455828541557763),\n",
      "   ('topic', 0.052709531277225996),\n",
      "   ('publish', 0.04312598013591218),\n",
      "   ('connection', 0.04112214671545565),\n",
      "   ('log', 0.037114479874542604),\n",
      "   ('broker', 0.036765987105767554),\n",
      "   ('certificate', 0.028750653423941452),\n",
      "   ('set', 0.025178602543997213),\n",
      "   ('connect', 0.016989022477783586)]),\n",
      " (4,\n",
      "  [('send', 0.16556976306882287),\n",
      "   ('datum', 0.12448288830387363),\n",
      "   ('receive', 0.0498307634449041),\n",
      "   ('event', 0.04484768710041369),\n",
      "   ('data', 0.02228281308762693),\n",
      "   ('platform', 0.02059044753666792),\n",
      "   ('node_re', 0.017205716434749906),\n",
      "   ('packet', 0.0163595336592704),\n",
      "   ('rule', 0.015137269650244452),\n",
      "   ('trigger', 0.015137269650244452)]),\n",
      " (5,\n",
      "  [('server', 0.09036144578313253),\n",
      "   ('network', 0.048547129695251594),\n",
      "   ('connect', 0.03791637136782424),\n",
      "   ('internet', 0.03065201984408221),\n",
      "   ('web', 0.02985471296952516),\n",
      "   ('control', 0.02524805102763997),\n",
      "   ('connection', 0.02250177179305457),\n",
      "   ('local', 0.021970233876683204),\n",
      "   ('access', 0.020021261516654856),\n",
      "   ('mobile', 0.016743444365698086)]),\n",
      " (6,\n",
      "  [('problem', 0.051260813546843365),\n",
      "   ('time', 0.041045462911835084),\n",
      "   ('change', 0.03598380268728143),\n",
      "   ('work', 0.03432725934106387),\n",
      "   ('function', 0.0311982330204307),\n",
      "   ('write', 0.031106202834529726),\n",
      "   ('test', 0.026228602981778024),\n",
      "   ('system', 0.024940180379164366),\n",
      "   ('return', 0.0221792748021351),\n",
      "   ('read', 0.021074912571323393)]),\n",
      " (7,\n",
      "  [('device', 0.33814874264312467),\n",
      "   ('service', 0.05368289637952559),\n",
      "   ('cloud', 0.03067594078830034),\n",
      "   ('user', 0.030140895309434635),\n",
      "   ('base', 0.024879614767255216),\n",
      "   ('gateway', 0.024522917781344748),\n",
      "   ('case', 0.018459069020866775),\n",
      "   ('register', 0.01819154628143392),\n",
      "   ('understand', 0.017032281077224896),\n",
      "   ('question', 0.016497235598359195)]),\n",
      " (8,\n",
      "  [('sensor', 0.07899593946105574),\n",
      "   ('esp', 0.03922111480251015),\n",
      "   ('temperature', 0.02916205241786637),\n",
      "   ('read', 0.028792912513842746),\n",
      "   ('output', 0.020025839793281652),\n",
      "   ('display', 0.01698043558508675),\n",
      "   ('string', 0.01670358065706903),\n",
      "   ('state', 0.016611295681063124),\n",
      "   ('arduino', 0.015965300849021778),\n",
      "   ('turn', 0.015042451088962717)]),\n",
      " (9,\n",
      "  [('datum', 0.06698050875454245),\n",
      "   ('database', 0.0318797489263297),\n",
      "   ('store', 0.030558308556326397),\n",
      "   ('time', 0.020482325735051207),\n",
      "   ('query', 0.019326065411298315),\n",
      "   ('good', 0.01503138420878758),\n",
      "   ('process', 0.014866204162537165),\n",
      "   ('data', 0.013957713908159895),\n",
      "   ('table', 0.013709943838784275),\n",
      "   ('stream', 0.011397423191278493)]),\n",
      " (10,\n",
      "  [('error', 0.0950019076688287),\n",
      "   ('follow', 0.045402518122853876),\n",
      "   ('start', 0.028328882106066388),\n",
      "   ('set', 0.024608927890118277),\n",
      "   ('find', 0.02384586035864174),\n",
      "   ('key', 0.019267455169782524),\n",
      "   ('run', 0.01812285387256772),\n",
      "   ('generate', 0.017073636016787484),\n",
      "   ('fail', 0.016787485692483783),\n",
      "   ('exception', 0.01631056848531095)]),\n",
      " (11,\n",
      "  [('azure', 0.07142857142857142),\n",
      "   ('hub', 0.06150520730988406),\n",
      "   ('follow', 0.03202986834348595),\n",
      "   ('show', 0.02996659461583808),\n",
      "   ('create', 0.029770092356062094),\n",
      "   ('sample', 0.024562782471998428),\n",
      "   ('issue', 0.02426802908233445),\n",
      "   ('module', 0.021811750835134605),\n",
      "   ('step', 0.019650225977598742),\n",
      "   ('find', 0.018864216938494792)])]\n",
      "\n",
      "\n",
      "\n",
      "Grau de CoerÃªncia:  0.43654861794118255 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>percentage</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>run, file, window, raspberry_pi, build, core, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>server, network, connect, internet, web, contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>sensor, esp, temperature, read, output, displa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>datum, database, store, time, query, good, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>client, message, topic, publish, connection, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>device, service, cloud, user, base, gateway, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>azure, hub, follow, show, create, sample, issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>send, datum, receive, event, data, platform, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>create, command, request, aw, update, thing, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>app, application, android, project, work, meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>error, follow, start, set, find, key, run, gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>problem, time, change, work, function, write, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic  percentage  \\\n",
       "0              0.0      0.1133   \n",
       "1              5.0      0.1127   \n",
       "2              8.0      0.0961   \n",
       "3              9.0      0.0943   \n",
       "4              3.0      0.0876   \n",
       "5              7.0      0.0815   \n",
       "6             11.0      0.0815   \n",
       "7              4.0      0.0812   \n",
       "8              2.0      0.0765   \n",
       "9              1.0      0.0625   \n",
       "10            10.0      0.0581   \n",
       "11             6.0      0.0549   \n",
       "\n",
       "                                       Topic_Keywords  \n",
       "0   run, file, window, raspberry_pi, build, core, ...  \n",
       "1   server, network, connect, internet, web, contr...  \n",
       "2   sensor, esp, temperature, read, output, displa...  \n",
       "3   datum, database, store, time, query, good, pro...  \n",
       "4   client, message, topic, publish, connection, l...  \n",
       "5   device, service, cloud, user, base, gateway, c...  \n",
       "6   azure, hub, follow, show, create, sample, issu...  \n",
       "7   send, datum, receive, event, data, platform, n...  \n",
       "8   create, command, request, aw, update, thing, a...  \n",
       "9   app, application, android, project, work, meth...  \n",
       "10  error, follow, start, set, find, key, run, gen...  \n",
       "11  problem, time, change, work, function, write, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import json\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', '&quot', 'datum', 'work', 'connect', 'code', 'iot', 'make', 'add', 'message', 'follow', 'solution', 'day'])\n",
    "\n",
    "datafile = json.load(codecs.open('data.json', 'r', 'utf-8-sig'))\n",
    "\n",
    "data = []\n",
    "for item in datafile[\"items\"]:\n",
    "    data.append(item[\"body\"])\n",
    "    \n",
    "#Remove Emoji\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "    \n",
    "data_notags = []\n",
    "#Remove tags and break lines\n",
    "for item in data:\n",
    "    data_bl = item.replace('\\n', ' ').replace('\\r', '')\n",
    "    data_nc = re.sub(r'<pre>.+?</pre>', '', data_bl)\n",
    "    data_ne = deEmojify(data_nc)\n",
    "    data_nt = BeautifulSoup(data_ne, \"lxml\").text\n",
    "\n",
    "    data_notags.append(data_nt)\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data_notags))\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_trigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "id2word.filter_extremes(no_below=2, no_above=1.0)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "mallet_path = 'C:/Users/ThIaG/PycharmProjects/lda3/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=12, id2word=id2word)\n",
    "\n",
    "\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(num_topics = 12, formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\n\\n\\nGrau de CoerÃªncia: ', coherence_ldamallet, '\\n\\n')\n",
    "\n",
    "def create_file():\n",
    "    path = \"files/topico\"\n",
    "    ext = \".json\"\n",
    "    for i in range(0,12):\n",
    "        os.remove(path + str(i) + ext)\n",
    "        open(path + str(i) + ext, \"x\")\n",
    "        \n",
    "\n",
    "def save_data(index, topic_num, data):\n",
    "    json_object = json.dumps(data[\"items\"][index])\n",
    "    with open(\"files/topico\"+ str(topic_num) + \".json\", \"a\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "\n",
    "def format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=data, alldata=datafile):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    create_file()\n",
    "    \n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                save_data(i, topic_num, alldata)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=data, alldata=datafile)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "topic_contribution = topic_contribution.rename_axis('Dominant_Topic').reset_index(name='percentage')\n",
    "\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']].drop_duplicates()\n",
    "topic_num_keywords.index = range(len(topic_num_keywords))\n",
    "\n",
    "df_dominant_topics = pd.merge(topic_contribution, topic_num_keywords, how='inner', on='Dominant_Topic')\n",
    "df_dominant_topics.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5eafd7-9f23-4c36-a1ce-023f6da2bada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5736706-011c-418d-be30-59cb6478971a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
